{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Twitter US Airline Sentiment dataset available on Kaggle](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment) is a collection of tweets from customers of major US airlines. The dataset was originally created by CrowdFlower and contains 14,640 tweets that were posted on Twitter in February 2015. Each tweet in the dataset is labeled with a sentiment (positive, negative, or neutral) towards the airline that the customer was addressing in the tweet.\n",
    "\n",
    "The dataset includes a range of information about each tweet, including the tweet text, the airline being addressed, the time the tweet was posted, the user's location and the user's Twitter handle.\n",
    "\n",
    "The main goal of this dataset is to enable researchers and data scientists to build models that can accurately predict the sentiment of customer tweets towards different airlines. This type of analysis can help airlines to better understand customer feedback and improve their overall customer service and experience.\n",
    "\n",
    "The dataset has been widely used in natural language processing and sentiment analysis research, and many studies have been conducted using this dataset to explore various aspects of sentiment analysis, such as feature selection, model building, and performance evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gCOQO8eqfvH"
   },
   "source": [
    "# Load and Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhUXWZFs_z3K",
    "outputId": "60ae8c82-acd4-4d97-d8c7-fffb605a68b3"
   },
   "outputs": [],
   "source": [
    "# install autotime package to track time execution of cells\n",
    "!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ImutW6Nj6QAm",
    "outputId": "570207d5-5350-4634-9289-2939a19876f9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vF46ZCgeT5hb"
   },
   "source": [
    "Read the data from the drive file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ic-380j6QDJ",
    "outputId": "aba9f157-2995-4ce0-85d6-edb5d2fee310"
   },
   "outputs": [],
   "source": [
    "Tweets = pd.read_csv('https://drive.google.com/uc?id=16BQRafnVEFMTAARipirqXoIdP-FBEGvJ')\n",
    "Tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtVmDCIGUIXK"
   },
   "source": [
    "### Question 1: Show first 2 lines of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "0jCJRaD585Ii",
    "outputId": "5a296f7c-f125-4204-927b-64233c1865e7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbGt1gkUUVNj"
   },
   "source": [
    "### Question 2: For our study, we will only need few column. Let's subset the dataframe to keep only the column:\n",
    "\n",
    "\n",
    "*  **airline**: Name of the company tagged in the tweet.\n",
    "*  **retweet_count**: number of retweet.\n",
    "*  **text**: content of the tweet.\n",
    "*  **tweet_created**: time of publication of the tweet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: add column to your dataframe that stores the size of your \"text\" string. Then filter your dataframe to keep only tweets that are above 75 chars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 855
    },
    "id": "WUKH0rUjkYG3",
    "outputId": "f285eb12-5eba-4f68-bedb-27dea689edc2"
   },
   "source": [
    "### Question 4: Using plotly express, can you plot the histogram for the text size and a barpot of number of tweets per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question5: Plotying number of tweets overtime.\n",
    "    - First convert your 'tweet_created' column to datetime.\n",
    "    - Create new column 'date' that contains only the day without timestamp\n",
    "    - Plot number of tweets per company per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcZTlN7qqTkk"
   },
   "source": [
    "# NLP with transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leuZmxDjqtJL"
   },
   "source": [
    "Install transformers from HuggingFace. Here is the official website https://huggingface.co/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-B86dyl9unJ"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ucK50-hrlvp"
   },
   "source": [
    "When using Neural Network, it's usual better to work with GPU device (specially for training). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DBo2d1B9uwC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU: \", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tk-FfdqviqW"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-w6DJvz-rL2s"
   },
   "source": [
    "### Question 6: Load the sentiment analysis pipeline \n",
    "the default package is **distilbert-base-uncased-finetuned-sst-2-english**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Apply the model\n",
    " - First check that the model is working properly and 10 lines of your dataset.\n",
    " - Run the model on your whole data.\n",
    " - Add new column to your dataset data contains the predicted label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "US4y7EeBvP6x"
   },
   "source": [
    "### Question 8:  barpot showing the number of positive and negative tweets per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: Translate the first 10 tweets to french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhwGLRFkwmNd"
   },
   "source": [
    "### Question 10:  Summarize  the first 10 tweets into 5 to 15 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insall BERTopic package. you can find the documentation in this repo: https://github.com/MaartenGr/BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "\n",
    "# Instantiate the Bertopic model\n",
    "model = BERTopic(language='english', calculate_probabilities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling can be sensitive to the quality of the data, it's using intersting to apply some cleaning before starting the modeling. in our case, we will start by removing the must frequet taggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Tweets = pd.read_csv('https://drive.google.com/uc?id=1zETU43nVhUvJQ2yrxaKuiFkGF8EaqD3z')\n",
    "Tweets.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11: can create new column 'clen_text' and remove all taggs for airline companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_companies = '@VirginAmerica|@AmericanAir|@JetBlue|@SouthwestAir|@united|@USAirways'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12: can you improve the cleaning of your text data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13: train the model and clean_text with size bigger than 110 characters (use fit fonction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14: use get_topic_info and visualize_barchart function to explore found topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15: Predict the topics of all the dataset with 75 characters and add main_topic column to your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16: Propose few plots to show the main topics per company and per sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 17: Propose a way to include retweets in your study/plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 18: Can you try to use \"zero-shot-classification\" to classify your tweets using these labels : Very positive, Positive, Neutral,  Negative, Very negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
